{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joke Punchline Generator - Project Report\n",
    "\n",
    "\n",
    "**SRN**- PES2UG23CS171\n",
    "\n",
    "**NAME**- Dhrushaj Achar\n",
    "\n",
    "**CLASS**- 6C CSE\n",
    "\n",
    "\n",
    "**Project Title:** Joke Punchline Generator\n",
    "\n",
    "**Goal:** Create a system that takes a joke setup as input (e.g., \"Why did the chicken cross the road?\") and uses AI to generate a funny punchline to complete the joke.\n",
    "\n",
    "**Technology:** Text generation using Hugging Face's `pipeline('text-generation')`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract\n",
    "\n",
    "This project implements an AI-powered joke punchline generator that uses natural language processing to complete joke setups. The system leverages the GPT-2 language model through Hugging Face's Transformers library to generate creative and contextually relevant punchlines. Users can input any joke setup, and the AI will automatically generate a completion, making it useful for entertainment, creative writing, or understanding how language models work with humor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documentation\n",
    "\n",
    "### What I Understood\n",
    "\n",
    "The main objective of this project was to build a text generation application that could understand the context of a joke setup and generate an appropriate punchline. I learned that:\n",
    "\n",
    "1. **Text Generation Pipeline:** Hugging Face provides a simple `pipeline('text-generation')` interface that abstracts away the complexity of loading and using pre-trained language models.\n",
    "\n",
    "2. **GPT-2 Model:** GPT-2 is a transformer-based language model trained on a large corpus of text. It can predict what comes next in a sequence, making it suitable for completing joke setups.\n",
    "\n",
    "3. **Parameters Matter:** The quality of generated text depends on parameters like:\n",
    "   - `max_new_tokens`: Controls how long the generated punchline will be\n",
    "   - `temperature`: Controls randomness (higher = more creative, lower = more predictable)\n",
    "   - `do_sample`: Enables sampling for more diverse outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "\n",
    "### Step 1: Install Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\dhrus\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (4.57.1)\n",
      "Requirement already satisfied: torch in c:\\users\\dhrus\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.9.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\dhrus\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (3.19.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in c:\\users\\dhrus\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\dhrus\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (2.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\dhrus\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\dhrus\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\dhrus\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (2025.11.3)\n",
      "Requirement already satisfied: requests in c:\\users\\dhrus\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\dhrus\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\dhrus\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\dhrus\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\dhrus\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.7.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\dhrus\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.14.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\dhrus\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\dhrus\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\dhrus\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\dhrus\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\dhrus\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\dhrus\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\dhrus\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\dhrus\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->transformers) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dhrus\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dhrus\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dhrus\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->transformers) (2025.10.5)\n"
     ]
    }
   ],
   "source": [
    "# Install required libraries (run this once)\n",
    "!pip install transformers torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Import Libraries and Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dhrus\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading AI model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from transformers import pipeline\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Initialize text generation pipeline\n",
    "print(\"Loading AI model...\")\n",
    "generator = pipeline('text-generation', model='gpt2')\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Define Punchline Generation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_punchline(setup):\n",
    "    \"\"\"Generate a punchline using AI text generation.\"\"\"\n",
    "    \n",
    "    prompt = f\"{setup} \"\n",
    "    \n",
    "    # Generate text\n",
    "    result = generator(\n",
    "        prompt,\n",
    "        max_new_tokens=30,\n",
    "        num_return_sequences=1,\n",
    "        temperature=0.8,\n",
    "        do_sample=True,\n",
    "        pad_token_id=generator.tokenizer.eos_token_id\n",
    "    )\n",
    "    \n",
    "    # Extract the generated text and remove the setup\n",
    "    generated_text = result[0]['generated_text']\n",
    "    punchline = generated_text[len(setup):].strip()\n",
    "    \n",
    "    return punchline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Test with Example Jokes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Joke Punchline Generator - Examples ===\n",
      "\n",
      "Setup: Why did the chicken cross the road?\n",
      "Punchline: I was pretty sure we were going to die trying.  \"Oh, hey!  Look at that white chicken's foot!\"\n",
      "--------------------------------------------------\n",
      "Setup: Why do programmers prefer dark mode?\n",
      "Punchline: Because I get to work with that too.  If you go dark mode, you may not be able to do your job at all.\n",
      "--------------------------------------------------\n",
      "Setup: How many developers does it take to change a light bulb?\n",
      "Punchline: Does it matter how many or how many colors of LED your light bulb has?  Do you need to do more to improve the way you\n",
      "--------------------------------------------------\n",
      "Setup: Knock knock!\n",
      "Punchline: (You can't kill me!)  I'd rather have this than my dead body.  I mean, this is just how real\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Example jokes\n",
    "examples = [\n",
    "    \"Why did the chicken cross the road?\",\n",
    "    \"Why do programmers prefer dark mode?\",\n",
    "    \"How many developers does it take to change a light bulb?\",\n",
    "    \"Knock knock!\"\n",
    "]\n",
    "\n",
    "print(\"=== Joke Punchline Generator - Examples ===\\n\")\n",
    "for setup in examples:\n",
    "    punchline = generate_punchline(setup)\n",
    "    print(f\"Setup: {setup}\")\n",
    "    print(f\"Punchline: {punchline}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Try Your Own Joke Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup: Why did the programmer quit his job?\n",
      "Punchline: The programmers who worked at IBM became part of the next wave of computer-makers.  In the early 1990s, many were hired by\n"
     ]
    }
   ],
   "source": [
    "# Try your own joke setup\n",
    "your_setup = \"Why did the programmer quit his job?\"\n",
    "\n",
    "punchline = generate_punchline(your_setup)\n",
    "print(f\"Setup: {your_setup}\")\n",
    "print(f\"Punchline: {punchline}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What I Built\n",
    "\n",
    "I developed a Jupyter Notebook application with the following features:\n",
    "\n",
    "**Core Functionality:**\n",
    "- Loads the GPT-2 model using Hugging Face's Transformers library\n",
    "- Takes joke setups as input\n",
    "- Generates AI-powered punchlines using text generation\n",
    "- Provides example jokes and allows custom inputs\n",
    "\n",
    "**Technical Implementation:**\n",
    "- Used `pipeline('text-generation', model='gpt2')` as the core AI engine\n",
    "- Configured generation parameters for optimal joke completion\n",
    "- Implemented warning suppression for cleaner output\n",
    "\n",
    "### How It Works\n",
    "\n",
    "1. The notebook initializes by loading the GPT-2 model (downloads on first run)\n",
    "2. When given a joke setup, it treats it as a text prompt\n",
    "3. The AI model analyzes the context and generates a continuation\n",
    "4. The generated text is extracted and presented as the punchline\n",
    "5. Users can modify the setup in the cells and run them to generate new punchlines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenges Faced\n",
    "\n",
    "- **Warning Messages:** Initially, the model generated warnings about conflicting parameters. I resolved this by using `max_new_tokens` instead of `max_length` and suppressing unnecessary warnings.\n",
    "- **Model Size:** The GPT-2 model is about 500MB, so the first run requires downloading it.\n",
    "- **Output Quality:** Text generation can sometimes produce unexpected results, so parameter tuning was necessary.\n",
    "\n",
    "## Future Improvements\n",
    "\n",
    "- Add support for larger models (GPT-2 Medium/Large) for better joke quality\n",
    "- Implement fine-tuning on a joke dataset for more humorous outputs\n",
    "- Add a rating system to evaluate punchline quality\n",
    "- Generate multiple punchlines and let users choose the best one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This project successfully demonstrates the application of AI text generation for creative purposes. By using the Hugging Face Transformers library and the GPT-2 model, I was able to create a functional joke punchline generator that showcases how modern NLP models can understand context and generate human-like text. The project helped me understand the practical implementation of text generation pipelines and the importance of parameter tuning in AI applications."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
